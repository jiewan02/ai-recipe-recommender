# Eat Smart! â€“ AI Recipe Recommendation Service

This project is a recipe recommendation system built with
React (frontend) â€“ Express (Node.js backend) â€“ Flask (model server).

It uses graph-based RAG, embedding search, and LLM-based recommendation
to suggest recipes tailored to the userâ€™s natural-language prompt and current situation.

---

## Project Structure
```
mini_project2/
â”œâ”€ client/          # React frontend
â”œâ”€ backend/         # Node.js (Express) server
â”œâ”€ model-server/    # Flask model server (conda environment)
â””â”€ codes/           # Data preprocessing & utility Python scripts
```


---

## ğŸš€ Quick Start (Run Order)

1. **client (React)** â€“ User Interface
2. **backend (Express)** â€“ Receives requests from the frontend and calls the model server
3. **model-server (Flask)** â€“ Handles models, embeddings, and RAG-based search

---

# 1ï¸âƒ£ Client (React)

### ğŸ“Œ Setup

```bash
cd client
npm install
npm start
```

---

# 2ï¸âƒ£ Backend (Express)

### ğŸ“Œ Setup

```bash
cd backend
npm install
npm start
```

---

# 3ï¸âƒ£ Model Server (Flask)

### ğŸ“Œ Setup

```bash
cd model-server
conda create -n recipe-model python=3.10 -y
conda activate recipe-model
pip install -r requirements.txt
python app.py
```

â€» The model server is recommended to run inside a conda environment.
* We use the Qwen-14B-Instruct model from Hugging Face. It is recommended to download the model inside the model-server/ directory.
---

### .env File (Required when using OpenAI API)
Create a file at model-server/.env and add:
```
OPENAI_API_KEY=your_openai_api_key
```

ğŸ—‚ Tech Stack

Frontend
	â€¢	React
	â€¢	Fetch API
	â€¢	React Hooks

Backend
	â€¢	Node.js
	â€¢	Express.js
	â€¢	REST API
	â€¢	Flask ì—°ë™

Model Server
	â€¢	Python 3.10+
	â€¢	Flask
	â€¢	Transformers / FAISS / Graph RAG ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
	â€¢	Conda Environment

Others
	â€¢	Preprocessing scripts (Python)
	â€¢	Embedding / Keyword extraction
	â€¢	Graph construction

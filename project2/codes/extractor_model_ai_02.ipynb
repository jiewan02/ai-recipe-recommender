{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a232da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: transformers in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: accelerate in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (0.48.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai transformers accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/fridge/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OpenAI client...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# =========================================================\n",
    "# 0. ëª¨ë¸ ê²½ë¡œ & 4bit ì„¤ì • (ì›ë˜ ì½”ë“œ ìœ ì§€)\n",
    "#    ğŸ‘‰ ì´ì œëŠ” ë¡œì»¬ Qwen ëŒ€ì‹  OpenAI API ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©\n",
    "# =========================================================\n",
    "\n",
    "# MODEL_NAME = \"/home/alpaco/lhc/Qwen2.5-14B-Instruct\"  # ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ê²½ë¡œ/ì´ë¦„\n",
    "MODEL_NAME = \"gpt-4.1-mini\"  # OpenAI APIì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (í•„ìš”ì‹œ gpt-4o ë“±ìœ¼ë¡œ ë³€ê²½)\n",
    "\n",
    "# 3 x 3090 (ê° 24GB) ê¸°ì¤€: 4bit ë¡œë“œ + device_map=\"auto\"\n",
    "# ğŸ‘‰ OpenAI API ì‚¬ìš© ì‹œì—ëŠ” ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì„¤ì •ì´ì§€ë§Œ,\n",
    "#    ì›ë˜ ì½”ë“œ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ í•œë„ ì§€ì • (í•„ìš”ì‹œ)\n",
    "# ğŸ‘‰ ë§ˆì°¬ê°€ì§€ë¡œ OpenAI APIì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "max_memory = {\n",
    "    0: \"20GiB\",   # ì—¬ìœ ë¥¼ ì¡°ê¸ˆ ë‚¨ê²¨ë‘ê¸°\n",
    "    1: \"20GiB\",\n",
    "    2: \"20GiB\",\n",
    "    \"cpu\": \"32GiB\",\n",
    "}\n",
    "\n",
    "print(\"Loading OpenAI client...\")\n",
    "\n",
    "# ğŸ”¹ OpenAI API í‚¤ ì„¤ì • (ì—¬ê¸°ì— ë³¸ì¸ í‚¤ ë„£ìœ¼ì„¸ìš”)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# ğŸ”¹ OpenAI Python SDK í´ë¼ì´ì–¸íŠ¸\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# ğŸ”¹ ë¡œì»¬ Qwen ëª¨ë¸ì€ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ placeholder ë¡œ ë‘¡ë‹ˆë‹¤.\n",
    "tokenizer = None\n",
    "model = None\n",
    "\n",
    "# Qwenì€ eos_token_id / pad_token_id ì„¤ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ\n",
    "# ğŸ‘‰ ì´ì œëŠ” ëª¨ë¸ì„ ì§ì ‘ ë¡œë“œí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì•„ë˜ if ë¸”ë¡ì€ ì˜ë¯¸ê°€ ì—†ì–´ì§‘ë‹ˆë‹¤.\n",
    "#    í•˜ì§€ë§Œ ì›ë˜ ì½”ë“œ êµ¬ì¡°/ì£¼ì„ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ë‚¨ê²¨ ë‘¡ë‹ˆë‹¤.\n",
    "if hasattr(torch, \"Tensor\"):  # í˜•ì‹ìƒ ì¡°ê±´ (ì‹¤ì œ ë™ì‘ X)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbaaf27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 1. SYSTEM PROMPT (í™•ì¥ëœ JSON ìŠ¤í‚¤ë§ˆ)\n",
    "# =========================================================\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë ˆì‹œí”¼ ì¶”ì²œ ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œì¸\n",
    "\"ìš”ë¦¬ ì˜ë„Â·ì¡°ê±´ ì¶”ì¶œê¸°(Keyword & Constraint Extractor)\" ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”:\n",
    "ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ë¦¬ ìš”ì²­ì—ì„œ **ëª¨ë“  ì˜ë¯¸ ìˆëŠ” ìš”ì†Œë¥¼ ë¹ ì§ì—†ì´ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¶œë ¥ ê·œì¹™ì€ ë°˜ë“œì‹œ ë‹¤ìŒì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ“Œ **â‘  ì¶œë ¥ í˜•ì‹**\n",
    "\n",
    "ì˜¤ì§ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆ í˜•íƒœì˜ JSONë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.\n",
    "ë¬¸ì¥ ì„¤ëª…, í•´ì„¤, ì¶”ê°€ ë¬¸êµ¬ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n",
    "ë¬´ì¡°ê±´ ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•˜ì‹­ì‹œì˜¤.\n",
    "\n",
    "ëª¨ë“  í•„ë“œëŠ” ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ê°’ì´ ë¹„ì—ˆìœ¼ë©´ **ë¹ˆ ë°°ì—´ ë˜ëŠ” null** ë¡œ ì±„ìš°ì‹­ì‹œì˜¤.\n",
    "\n",
    "JSON ìŠ¤í‚¤ë§ˆ:\n",
    "\n",
    "{\n",
    "  \"dish_type\": [],                    // ìš”ë¦¬ í˜•íƒœ/ì¢…ë¥˜\n",
    "  \"method\": [],                       // ì¡°ë¦¬ ë°©ì‹\n",
    "  \"situation\": [],                    // ë¨¹ëŠ” ìƒí™©/ë§¥ë½\n",
    "  \"must_ingredients\": [],             // ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ì¬ë£Œ\n",
    "  \"optional_ingredients\": [],         // ë“¤ì–´ê°€ë©´ ì¢‹ì§€ë§Œ í•„ìˆ˜ëŠ” ì•„ë‹Œ ì¬ë£Œ\n",
    "  \"exclude_ingredients\": [],          // ì ˆëŒ€ ë“¤ì–´ê°€ë©´ ì•ˆ ë˜ëŠ” ì¬ë£Œ\n",
    "  \"spiciness\": \"none\" | \"low\" | \"medium\" | \"high\" | null,\n",
    "\n",
    "  \"dietary_constraints\": {\n",
    "    \"vegetarian\": bool,\n",
    "    \"vegan\": bool,\n",
    "    \"no_beef\": bool,\n",
    "    \"no_pork\": bool,\n",
    "    \"no_chicken\": bool,\n",
    "    \"no_seafood\": bool\n",
    "  },\n",
    "\n",
    "  \"servings\": {\n",
    "    \"min\": int or null,\n",
    "    \"max\": int or null\n",
    "  },\n",
    "\n",
    "  \"max_cook_time_min\": int or null,\n",
    "  \"difficulty\": [],\n",
    "\n",
    "  \"health_tags\": [],                  // ê±´ê°•, ëª©ì , ì˜ì–‘ ê´€ë ¨\n",
    "  \"weather_tags\": [],                 // ë‚ ì”¨/ê³„ì ˆ\n",
    "  \"menu_style\": [],                   // êµ­ê°€/ë¶„ë¥˜/ìŠ¤íƒ€ì¼\n",
    "  \"extra_keywords\": [],               // ìœ„ ì–´ë””ì—ë„ ì†í•˜ì§€ ì•ŠëŠ” ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´\n",
    "\n",
    "  \"positive_tags\": [],                // ì‚¬ìš©ìê°€ ì›í•¨/ì¢‹ì•„í•¨\n",
    "  \"negative_tags\": [],                // ì‚¬ìš©ìê°€ ì‹«ì–´í•¨/í”¼í•˜ê³  ì‹¶ìŒ\n",
    "\n",
    "  \"free_text\": string                 // ì „ì²´ ìš”ì²­ì˜ ìì—°ì–´ ìš”ì•½\n",
    "}\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ“Œ **â‘¡ ê° í•„ë“œì˜ ì„¸ë¶€ ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)**\n",
    "\n",
    "1) dish_type (ìš”ë¦¬ ì¢…ë¥˜)\n",
    "- \"ì°Œê°œ\", \"êµ­\", \"ë³¶ìŒ\", \"íŠ€ê¹€\", \"ì¡°ë¦¼\", \"ë®ë°¥\", \"ë¹„ë¹”ë°¥\", \"ë©´ ìš”ë¦¬\" ë“±\n",
    "- ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì  í‘œí˜„ìœ¼ë¡œ ì¶”ì¶œ\n",
    "\n",
    "2) method (ì¡°ë¦¬ ë°©ì‹)\n",
    "- \"ë“ì´ê¸°\", \"ë³¶ê¸°\", \"ì°œ\", \"ë¬´ì¹¨\", \"íŠ€ê¸°ê¸°\", \"êµ½ê¸°\" ë“±\n",
    "\n",
    "3) situation (ë¨¹ëŠ” ìƒí™©)\n",
    "- \"ì•¼ì‹\", \"í˜¼ë°¥\", \"ìˆ ì•ˆì£¼\", \"ì†ë‹˜ ì´ˆëŒ€\", \"ê°„ë‹¨í•˜ê²Œ\", \"ë„ì‹œë½\", \"ìº í•‘\" ë“±\n",
    "- ë¬¸ë§¥ì—ì„œ ìˆ¨ê²¨ì§„ ìƒí™©ë„ ì¶”ë¡ í•˜ì—¬ í¬í•¨ ê°€ëŠ¥\n",
    "\n",
    "4) must_ingredients ê·œì¹™(ì•„ì£¼ ì¤‘ìš”):\n",
    "\n",
    "  ì‚¬ìš©ìê°€ íŠ¹ì • ì¬ë£Œë¥¼ ì–¸ê¸‰í•˜ë©° â€œ~ ìš”ë¦¬ ì¶”ì²œí•´ì¤˜â€, â€œ~ ë„£ì–´ ë¨¹ê³  ì‹¶ë‹¤â€, \n",
    "  â€œ~ë¡œ ë§Œë“¤ê³  ì‹¶ë‹¤â€, â€œ~ ìš”ë¦¬ê°€ ë•¡ê¸´ë‹¤â€, â€œ~ ìš”ë¦¬ ë¨¹ê³  ì‹¶ì–´â€ ë¼ê³  ë§í•œ ê²½ìš°\n",
    "  â†’ í•´ë‹¹ ì¬ë£ŒëŠ” MUST INGREDIENTë¡œ ê°„ì£¼í•œë‹¤.\n",
    "\n",
    "  ì˜ˆ:\n",
    "  - â€œë¼ì§€ê³ ê¸° ìš”ë¦¬ ì¶”ì²œí•´ì¤˜â€ â†’ must_ingredients: [\"ë¼ì§€ê³ ê¸°\"]\n",
    "  - â€œê¹€ì¹˜ë‘ ë²„ì„¯ì´ë‘ ê°™ì´ ë¨¹ê³  ì‹¶ë‹¤â€ â†’ must_ingredients: [\"ê¹€ì¹˜\",\"ë²„ì„¯\"]\n",
    "  - â€œë‹­ê³ ê¸°ë¡œ ë­˜ ë§Œë“¤ê¹Œ?â€ â†’ must_ingredients: [\"ë‹­ê³ ê¸°\"]\n",
    "\n",
    "5) optional_ingredients\n",
    "- â€œìˆìœ¼ë©´ ì¢‹ê³ â€, â€œê°€ëŠ¥í•˜ë©´â€, â€œì¶”ê°€ë¡œâ€ í‘œí˜„ëœ ì¬ë£Œ\n",
    "\n",
    "6) exclude_ingredients\n",
    "- â€œì‹«ì–´â€, â€œì•Œë ˆë¥´ê¸°â€, â€œëª»ë¨¹ì–´â€, â€œë¹¼ê³ â€, â€œì œì™¸í•´ì¤˜â€ ë“±\n",
    "\n",
    "7) spiciness\n",
    "- \"ì•ˆ ë§¤ìš´\", \"ë§¤ì½¤í•˜ê²Œ\", \"ì–¼í°í•˜ê²Œ\" ë“± í•´ì„í•˜ì—¬ 4ë‹¨ê³„ë¡œ ì •ê·œí™”:\n",
    "  - none, low, medium, high\n",
    "\n",
    "8) dietary_constraints\n",
    "- \"ì±„ì‹ì£¼ì˜ì\" â†’ vegetarian=true + no_beef/no_pork/no_chicken/no_seafood=true, ì–´ë– í•œ í˜•íƒœì˜ ê³ ê¸°ìš”ë¦¬ë‚˜ ìƒì„ ìš”ë¦¬ë„ í¬í•¨ë˜ë©´ ì•ˆë¼\n",
    "- \"ë¹„ê±´\" â†’ vegan=true + ìœ„ ì¡°ê±´ ëª¨ë‘ true\n",
    "- â€œê³ ê¸° ì•ˆ ë¨¹ì–´â€ â†’ no_beef/no_pork/no_chicken ëª¨ë‘ true\n",
    "- íŠ¹ì • ìœ¡ë¥˜ë§Œ ì‹«ì–´í•˜ë©´ í•´ë‹¹ í•­ëª©ë§Œ true\n",
    "\n",
    "9) servings\n",
    "- \"1ì¸ë¶„\", \"í˜¼ì ë¨¹ì„ ê±°ì•¼\" â†’ min=1, max=1\n",
    "- \"4ëª…\", \"ê°€ì¡±\" â†’ ì¶”ë¡  ê°€ëŠ¥í•˜ë©´ ë„£ê³ , ë¶ˆí™•ì‹¤í•˜ë©´ null\n",
    "\n",
    "10) max_cook_time_min\n",
    "- \"10ë¶„ ì•ˆì—\", \"ë¹¨ë¦¬\", \"ê°„ë‹¨íˆ\" â†’ ëª…í™•íˆ ìˆ«ìê°€ ìˆì„ ë•Œë§Œ ê¸°ì…\n",
    "- ìˆ«ìê°€ ì—†ìœ¼ë©´ null\n",
    "\n",
    "11) difficulty\n",
    "- \"ê°„ë‹¨í•œ\", \"ì‰½ê²Œ\", \"ì–´ë ¤ìš´ ìš”ë¦¬\" ë“± ë‚œì´ë„ í‘œí˜„ ê·¸ëŒ€ë¡œ ë‹¨ì–´ë¡œ ë„£ê¸°\n",
    "\n",
    "12) health_tags\n",
    "- \"ë‹¤ì´ì–´íŠ¸\", \"ê³ ë‹¨ë°±\", \"ì €ì—¼ì‹\", \"ì €ì¹¼ë¡œë¦¬\", \"ì˜ì–‘ì‹\" ë“±\n",
    "\n",
    "13) weather_tags\n",
    "- \"ì¶”ìš´ ë‚ \", \"ë”ìš´ ë‚ \", \"ë¹„ì˜¤ëŠ” ë‚ \", \"ê²¨ìš¸\", \"ì—¬ë¦„\" ë“±\n",
    "\n",
    "14) menu_style\n",
    "- \"í•œì‹\", \"ì¤‘ì‹\", \"ì–‘ì‹\", \"ë¶„ì‹\", \"ë””ì €íŠ¸\", \"ì•ˆì£¼\", \"ë¸ŒëŸ°ì¹˜\", \"í•œ ê·¸ë¦‡\" ë“±\n",
    "\n",
    "15) extra_keywords\n",
    "- ìœ„ í•­ëª©ë“¤ ì–´ë””ì—ë„ ì†í•˜ì§€ ì•Šì§€ë§Œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´\n",
    "  ì˜ˆ: \"ë°±ì¢…ì› ë ˆì‹œí”¼\", \"ì—ì–´í”„ë¼ì´ì–´\", \"ëª…ì ˆ\", \"ì¹¼ì¹¼í•œ\", \"ê°„í¸ì‹\"\n",
    "\n",
    "16) positive_tags\n",
    "- â€œì¢‹ì•„í•´â€, â€œë¨¹ê³  ì‹¶ì–´â€, â€œì›í•´â€, â€œ craving â€ ë“± ê°ì •/ì„ í˜¸ ê¸°ë°˜\n",
    "\n",
    "17) negative_tags\n",
    "- â€œì‹«ì–´â€, â€œë³„ë¡œâ€, â€œêº¼ë ¤ì ¸â€, \"ë¨¹ê¸° ì‹«ì–´\"\n",
    "\n",
    "18) free_text\n",
    "- ì „ì²´ ì‚¬ìš©ì ìš”ì²­ì„ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•œ 1~3ë¬¸ì¥\n",
    "- ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ë‹¤ìŒ ë‚´ìš©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•¨:\n",
    "  1) ì‚¬ìš©ìê°€ ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–¤ ì¢…ë¥˜ì˜ ìŒì‹ì„ ì›í•˜ê³  ìˆëŠ”ì§€\n",
    "  2) ì¬ë£Œ/ì‹ë‹¨ ì œí•œ/ì·¨í–¥ ì¡°ê±´ì´ ì„œë¡œ ëª¨ìˆœë˜ê±°ë‚˜ ë¹„í˜„ì‹¤ì ì¸ì§€ ì—¬ë¶€\n",
    "  3) ëª¨ìˆœÂ·ìœ„í—˜Â·ë¹„í˜„ì‹¤ì ì¸ ì¡°ê±´ì´ ìˆë‹¤ë©´,\n",
    "     \"ìš”ì²­ì„ ê·¸ëŒ€ë¡œ ë§Œì¡±ì‹œí‚¤ê¸° ì–´ë µë‹¤\"ëŠ” ì ê³¼\n",
    "     ì–´ë–¤ ë°©í–¥(ì˜ˆ: ë¹„ê±´ ìœ ì§€, ì•Œë ˆë¥´ê¸° íšŒí”¼ ë“±)ì„ ìš°ì„ í•´ì•¼ í•˜ëŠ”ì§€ ì œì•ˆ\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ“Œ **â‘¢ ì ˆëŒ€ì ìœ¼ë¡œ ì§€ì¼œì•¼ í•  3ê°€ì§€**\n",
    "\n",
    "1. ì¶œë ¥ì€ ë°˜ë“œì‹œ **JSON ë‹¨ë…**ì´ì–´ì•¼ í•¨ (ì•ë’¤ ì¶”ê°€ í…ìŠ¤íŠ¸ ê¸ˆì§€)  \n",
    "2. JSON ìŠ¤í‚¤ë§ˆì˜ **ëª¨ë“  í•„ë“œ**ë¥¼ ë°˜ë“œì‹œ ì¶œë ¥  \n",
    "3. ë¹ˆ ê°’ë„ ë°˜ë“œì‹œ í¬í•¨ (ì ˆëŒ€ í•„ë“œ ëˆ„ë½ ê¸ˆì§€)\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "ì§€ê¸ˆë¶€í„° ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´\n",
    "ìœ„ ìŠ¤í‚¤ë§ˆì— ë§ì¶° **ì •í™•í•˜ê³  ì™„ì „í•œ JSON**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20fc36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 2. Post-process helpers\n",
    "# =========================================================\n",
    "\n",
    "def _ensure_list(x):\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        if not x.strip():\n",
    "            return []\n",
    "        return [x]\n",
    "    return list(x)\n",
    "\n",
    "def _unique_preserve_order(lst):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in lst:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "def _dedup_by_norm_space_lower(tags):\n",
    "    \"\"\"\n",
    "    ['ì¶”ìš´ ë‚ ', 'ì¶”ìš´ë‚ '] ê°™ì´ ê³µë°±/ëŒ€ì†Œë¬¸ìë§Œ ë‹¤ë¥¸ ì¤‘ë³µì„ í•˜ë‚˜ë¡œ ì •ë¦¬.\n",
    "    \"\"\"\n",
    "    norm_seen = set()\n",
    "    out = []\n",
    "    for t in _ensure_list(tags):\n",
    "        norm = str(t).replace(\" \", \"\").lower()\n",
    "        if norm in norm_seen:\n",
    "            continue\n",
    "        norm_seen.add(norm)\n",
    "        out.append(t)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _postprocess_text_to_json(output_text: str, fallback_prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    - LLMì´ ì¶œë ¥í•œ JSON í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±\n",
    "    - ëˆ„ë½/íƒ€ì… ì´ìƒ í•„ë“œ ë³´ì •\n",
    "    - positive_tags â†’ health_tags / extra_keywords í™•ì¥\n",
    "    - weather_tagsëŠ” LLM ì¶œë ¥ë§Œ ì‚¬ìš©í•˜ë˜, í‘œê¸° ì¤‘ë³µë§Œ ì •ë¦¬\n",
    "    \"\"\"\n",
    "    output_text = output_text.strip()\n",
    "\n",
    "    # ```json ... ``` í˜•íƒœ ì œê±°\n",
    "    if output_text.startswith(\"```\"):\n",
    "        output_text = output_text.strip(\"`\").strip()\n",
    "        if output_text.startswith(\"json\"):\n",
    "            output_text = output_text[4:].strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        data = {}\n",
    "\n",
    "    # 1) ê¸°ë³¸ ê³¨ê²© (í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ê¸°ì¤€)\n",
    "    base = {\n",
    "        \"dish_type\": [],\n",
    "        \"method\": [],\n",
    "        \"situation\": [],\n",
    "        \"must_ingredients\": [],\n",
    "        \"optional_ingredients\": [],\n",
    "        \"exclude_ingredients\": [],\n",
    "        \"spiciness\": None,\n",
    "        \"dietary_constraints\": {\n",
    "            \"vegetarian\": False,\n",
    "            \"vegan\": False,\n",
    "            \"no_beef\": False,\n",
    "            \"no_pork\": False,\n",
    "            \"no_chicken\": False,\n",
    "            \"no_seafood\": False,\n",
    "        },\n",
    "        \"servings\": {\"min\": None, \"max\": None},\n",
    "        \"max_cook_time_min\": None,\n",
    "        \"difficulty\": [],\n",
    "\n",
    "        \"health_tags\": [],\n",
    "        \"weather_tags\": [],\n",
    "        \"menu_style\": [],\n",
    "        \"extra_keywords\": [],\n",
    "\n",
    "        \"positive_tags\": [],\n",
    "        \"negative_tags\": [],\n",
    "        \"free_text\": fallback_prompt,\n",
    "    }\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        data = {}\n",
    "\n",
    "    merged = base.copy()\n",
    "    merged.update({k: v for k, v in data.items() if v is not None})\n",
    "\n",
    "    # ë¦¬ìŠ¤íŠ¸ í•„ë“œ ì •ê·œí™”\n",
    "    list_fields = [\n",
    "        \"dish_type\", \"method\", \"situation\",\n",
    "        \"must_ingredients\", \"optional_ingredients\", \"exclude_ingredients\",\n",
    "        \"difficulty\",\n",
    "        \"health_tags\", \"weather_tags\", \"menu_style\", \"extra_keywords\",\n",
    "        \"positive_tags\", \"negative_tags\",\n",
    "    ]\n",
    "    for k in list_fields:\n",
    "        merged[k] = _ensure_list(merged.get(k))\n",
    "\n",
    "    # dietary_constraints ë³´ì •\n",
    "    dc = merged.get(\"dietary_constraints\") or {}\n",
    "    merged[\"dietary_constraints\"] = {\n",
    "        \"vegetarian\": bool(dc.get(\"vegetarian\", False)),\n",
    "        \"vegan\": bool(dc.get(\"vegan\", False)),\n",
    "        \"no_beef\": bool(dc.get(\"no_beef\", False)),\n",
    "        \"no_pork\": bool(dc.get(\"no_pork\", False)),\n",
    "        \"no_chicken\": bool(dc.get(\"no_chicken\", False)),\n",
    "        \"no_seafood\": bool(dc.get(\"no_seafood\", False)),\n",
    "    }\n",
    "\n",
    "    # servings ë³´ì •\n",
    "    serv = merged.get(\"servings\") or {}\n",
    "    merged[\"servings\"] = {\n",
    "        \"min\": serv.get(\"min\"),\n",
    "        \"max\": serv.get(\"max\"),\n",
    "    }\n",
    "\n",
    "    # spiciness ì •ê·œí™”\n",
    "    valid_sp = {\"none\", \"low\", \"medium\", \"high\", None}\n",
    "    sp = merged.get(\"spiciness\")\n",
    "    if isinstance(sp, str):\n",
    "        sp = sp.lower().strip()\n",
    "        if sp not in valid_sp:\n",
    "            sp = None\n",
    "    elif sp not in valid_sp:\n",
    "        sp = None\n",
    "    merged[\"spiciness\"] = sp\n",
    "\n",
    "    # free_text ë³´ì •\n",
    "    if not isinstance(merged.get(\"free_text\"), str) or not merged[\"free_text\"].strip():\n",
    "        merged[\"free_text\"] = fallback_prompt\n",
    "\n",
    "    # positive_tags â†’ health_tags / extra_keywords í™•ì¥\n",
    "    pos = merged.get(\"positive_tags\", [])\n",
    "    merged[\"health_tags\"] = _unique_preserve_order(merged[\"health_tags\"] + pos)\n",
    "    merged[\"extra_keywords\"] = _unique_preserve_order(merged[\"extra_keywords\"] + pos)\n",
    "\n",
    "    # weather_tagsëŠ” LLM ì¶œë ¥ë§Œ ì‹ ë¢°, ëŒ€ì‹  ê³µë°±/ëŒ€ì†Œë¬¸ì ê¸°ì¤€ ì¤‘ë³µ ì œê±°\n",
    "    merged[\"weather_tags\"] = _dedup_by_norm_space_lower(merged[\"weather_tags\"])\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. ì‹¤ì œ í˜¸ì¶œ í•¨ìˆ˜: extract_keywords (ì›ë˜ chat_template ë°©ì‹ ìœ ì§€ â†’ OpenAI APIë¡œ ë³€ê²½)\n",
    "# =========================================================\n",
    "\n",
    "def extract_keywords(user_prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ ììœ  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ë ˆì‹œí”¼ ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œ.\n",
    "    - ê¸°ì¡´ì—ëŠ” 4bit Qwen2.5-14B (multi-GPU) ì‚¬ìš©\n",
    "    - ì´ì œëŠ” OpenAI Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬\n",
    "      SYSTEM_PROMPTì— ì •ì˜ëœ í™•ì¥ ìŠ¤í‚¤ë§ˆë¡œ\n",
    "      health_tags / weather_tags / menu_style / extra_keywordsê¹Œì§€ í¬í•¨\n",
    "    \"\"\"\n",
    "\n",
    "    # OpenAI Responses APIëŠ” instructions + input ì¡°í•©ìœ¼ë¡œ\n",
    "    # system / user ì—­í• ì„ ì¤„ ìˆ˜ ìˆìŒ.\n",
    "    # - instructions: SYSTEM_PROMPT (ì—­í• /ìŠ¤í‚¤ë§ˆ ì„¤ëª…)\n",
    "    # - input: ì‹¤ì œ user_prompt\n",
    "    response = client.responses.create(\n",
    "        model=MODEL_NAME,\n",
    "        instructions=SYSTEM_PROMPT,\n",
    "        input=user_prompt,\n",
    "        temperature=0.0,        # JSON í¬ë§· ìœ ì§€ ìœ„í•´ ìµœëŒ€í•œ ê²°ì •ì ìœ¼ë¡œ\n",
    "        max_output_tokens=256,  # ì›ë˜ max_new_tokens=128ë³´ë‹¤ëŠ” ì•½ê°„ ì—¬ìœ \n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ì´ ìƒì„±í•œ ìˆœìˆ˜ í…ìŠ¤íŠ¸(JSON ë¬¸ìì—´)\n",
    "    output_text = response.output_text or \"\"\n",
    "\n",
    "    return _postprocess_text_to_json(output_text, fallback_prompt=user_prompt)\n",
    "\n",
    "\n",
    "# íŒŒì¼ ë§¨ ì•„ë˜ ê·¼ì²˜\n",
    "__all__ = [\"extract_keywords\", \"tokenizer\", \"model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cf302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv íŒŒì¼ë¡œ ì €ì¥\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  CSV ê²½ë¡œ (ì›í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ ë°”ê¿”ë„ ë©ë‹ˆë‹¤)\n",
    "CSV_PATH = \"keyword_extract_log.csv\"\n",
    "\n",
    "\n",
    "def _join_list(x):\n",
    "    \"\"\"ë¦¬ìŠ¤íŠ¸ë¥¼ ' | 'ë¡œ ì´ì–´ë¶™ì—¬ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return \" | \".join(map(str, x))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def result_to_row(user_prompt: str, result: dict) -> dict:\n",
    "    \"\"\"\n",
    "    extract_keywords() ê²°ê³¼ dictë¥¼\n",
    "    CSV í•œ ì¤„(row) í˜•íƒœì˜ flat dictë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    dc = result.get(\"dietary_constraints\", {}) or {}\n",
    "    serv = result.get(\"servings\", {}) or {}\n",
    "\n",
    "    row = {\n",
    "        \"user_prompt\": user_prompt,\n",
    "\n",
    "        # ë¦¬ìŠ¤íŠ¸ í•„ë“œë“¤: \" | \" ë¡œ join\n",
    "        \"dish_type\": _join_list(result.get(\"dish_type\", [])),\n",
    "        \"method\": _join_list(result.get(\"method\", [])),\n",
    "        \"situation\": _join_list(result.get(\"situation\", [])),\n",
    "        \"must_ingredients\": _join_list(result.get(\"must_ingredients\", [])),\n",
    "        \"optional_ingredients\": _join_list(result.get(\"optional_ingredients\", [])),\n",
    "        \"exclude_ingredients\": _join_list(result.get(\"exclude_ingredients\", [])),\n",
    "        \"difficulty\": _join_list(result.get(\"difficulty\", [])),\n",
    "        \"health_tags\": _join_list(result.get(\"health_tags\", [])),\n",
    "        \"weather_tags\": _join_list(result.get(\"weather_tags\", [])),\n",
    "        \"menu_style\": _join_list(result.get(\"menu_style\", [])),\n",
    "        \"extra_keywords\": _join_list(result.get(\"extra_keywords\", [])),\n",
    "        \"positive_tags\": _join_list(result.get(\"positive_tags\", [])),\n",
    "        \"negative_tags\": _join_list(result.get(\"negative_tags\", [])),\n",
    "\n",
    "        # ë‹¨ì¼ ê°’ë“¤\n",
    "        \"spiciness\": result.get(\"spiciness\", None),\n",
    "\n",
    "        # diet ì œì•½ (bool)\n",
    "        \"vegetarian\": dc.get(\"vegetarian\", False),\n",
    "        \"vegan\": dc.get(\"vegan\", False),\n",
    "        \"no_beef\": dc.get(\"no_beef\", False),\n",
    "        \"no_pork\": dc.get(\"no_pork\", False),\n",
    "        \"no_chicken\": dc.get(\"no_chicken\", False),\n",
    "        \"no_seafood\": dc.get(\"no_seafood\", False),\n",
    "\n",
    "        # ì¸ë¶„ ì •ë³´\n",
    "        \"servings_min\": serv.get(\"min\", None),\n",
    "        \"servings_max\": serv.get(\"max\", None),\n",
    "\n",
    "        # ì‹œê°„, free_text\n",
    "        \"max_cook_time_min\": result.get(\"max_cook_time_min\", None),\n",
    "        \"free_text\": result.get(\"free_text\", \"\"),\n",
    "    }\n",
    "    return row\n",
    "\n",
    "\n",
    "def save_result_to_csv(user_prompt: str, result: dict, csv_path: str = CSV_PATH):\n",
    "    \"\"\"\n",
    "    - user_prompt + extract_keywords ê²°ê³¼ë¥¼ í•œ ì¤„(row)ë¡œ ë§Œë“¤ì–´ì„œ\n",
    "      csv_pathì— í•œ ì¤„ì”© ì¶”ê°€(append) ì €ì¥\n",
    "    - íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ë¥¼ ë¨¼ì € ì“°ê³ , ìˆìœ¼ë©´ í—¤ë” ì—†ì´ ë‚´ìš©ë§Œ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    row = result_to_row(user_prompt, result)\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "\n",
    "    with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def run_and_log(user_prompt: str, csv_path: str = CSV_PATH):\n",
    "    \"\"\"\n",
    "    í¸í•˜ê²Œ ì“°ë¼ê³  ë§Œë“  í—¬í¼ í•¨ìˆ˜:\n",
    "    - extract_keywords(user_prompt) ì‹¤í–‰\n",
    "    - ê²°ê³¼ë¥¼ CSVì— ì €ì¥\n",
    "    - ê²°ê³¼ dictë¥¼ ê·¸ëŒ€ë¡œ ë¦¬í„´\n",
    "    \"\"\"\n",
    "    result = extract_keywords(user_prompt)\n",
    "    save_result_to_csv(user_prompt, result, csv_path=csv_path)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ea9a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²˜ë¦¬ ì™„ë£Œ: ë¹„ì˜¤ë‹ˆê¹ ì „ì„ ë¨¹ê³ ì‹¶ì–´\n",
      "ì²˜ë¦¬ ì™„ë£Œ: í•´ë¬¼íƒ•ë§Œë“œëŠ” ë°©ë²•,ë‚˜ëŠ” ìƒˆìš° ì•ŒëŸ¬ì§€ê°€ ìˆì–´\n",
      "ì²˜ë¦¬ ì™„ë£Œ: ì•„ì´íŒ¨ë“œë¡œ ê±´ê°•ì‹ ì•Œë ¤ì¤˜\n",
      "ì²˜ë¦¬ ì™„ë£Œ: ë‹¹ê·¼ìœ¼ë¡œ ë§Œë“œëŠ” ì–¼í°í•œ íƒ• ì¶”ì²œí•´ì¤˜\n",
      "ì²˜ë¦¬ ì™„ë£Œ: ì˜¤ì´ë¡œ ë§Œë“œëŠ” ì°Œê°œ ì¶”ì²œ\n",
      "ì²˜ë¦¬ ì™„ë£Œ: ê¹€ìœ¼ë¡œ ë§Œë“œëŠ” ì†Œë³´ë¥´ë¹µ ë ˆì‹œí”¼\n",
      "ì²˜ë¦¬ ì™„ë£Œ: ê°ìë¡œ ê³ êµ¬ë§ˆê¹¡ ë§Œë‹¤ëŠ” ë°©ë²• ì•Œë ¤ì¤˜\n",
      "ì²˜ë¦¬ ì™„ë£Œ: í† ë¼ìƒ\n",
      "ì²˜ë¦¬ ì™„ë£Œ: í† ë¼ ê³ ê¸° ë§›ìˆê²Œ ë§Œë“œëŠ” ë°©ë²•\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"ë¹„ì˜¤ë‹ˆê¹ ì „ì„ ë¨¹ê³ ì‹¶ì–´\",\n",
    "    \"í•´ë¬¼íƒ•ë§Œë“œëŠ” ë°©ë²•,ë‚˜ëŠ” ìƒˆìš° ì•ŒëŸ¬ì§€ê°€ ìˆì–´\",\n",
    "    \"ì•„ì´íŒ¨ë“œë¡œ ê±´ê°•ì‹ ì•Œë ¤ì¤˜\",\n",
    "    \"ë‹¹ê·¼ìœ¼ë¡œ ë§Œë“œëŠ” ì–¼í°í•œ íƒ• ì¶”ì²œí•´ì¤˜\",\n",
    "    \"ì˜¤ì´ë¡œ ë§Œë“œëŠ” ì°Œê°œ ì¶”ì²œ\",\n",
    "    \"ê¹€ìœ¼ë¡œ ë§Œë“œëŠ” ì†Œë³´ë¥´ë¹µ ë ˆì‹œí”¼\",\n",
    "    \"ê°ìë¡œ ê³ êµ¬ë§ˆê¹¡ ë§Œë‹¤ëŠ” ë°©ë²• ì•Œë ¤ì¤˜\",\n",
    "    \"í† ë¼ìƒ\",\n",
    "    \"í† ë¼ ê³ ê¸° ë§›ìˆê²Œ ë§Œë“œëŠ” ë°©ë²•\"\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    r = run_and_log(p)\n",
    "    print(\"ì²˜ë¦¬ ì™„ë£Œ:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe24d9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dish_type': [],\n",
       " 'method': [],\n",
       " 'situation': [],\n",
       " 'must_ingredients': [],\n",
       " 'optional_ingredients': [],\n",
       " 'exclude_ingredients': [],\n",
       " 'spiciness': None,\n",
       " 'dietary_constraints': {'vegetarian': False,\n",
       "  'vegan': False,\n",
       "  'no_beef': False,\n",
       "  'no_pork': False,\n",
       "  'no_chicken': False,\n",
       "  'no_seafood': False},\n",
       " 'servings': {'min': None, 'max': None},\n",
       " 'max_cook_time_min': None,\n",
       " 'difficulty': [],\n",
       " 'health_tags': [],\n",
       " 'weather_tags': [],\n",
       " 'menu_style': [],\n",
       " 'extra_keywords': [],\n",
       " 'positive_tags': [],\n",
       " 'negative_tags': [],\n",
       " 'free_text': 'ì‚¬ìš©ìì˜ ì…ë ¥ì—ì„œ ìš”ë¦¬ ì˜ë„ë‚˜ ì¡°ê±´ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = \"ì§€ì™„ì´ëŠ” ë„ë§ê°”ë‹¤\"\n",
    "result = extract_keywords(test_prompt)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ab95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import torch
import json
import os
from openai import OpenAI

# =========================================================
# 0. ëª¨ë¸ ê²½ë¡œ & 4bit ì„¤ì • (ì›ë˜ ì½”ë“œ ìœ ì§€)
#    ğŸ‘‰ ì´ì œëŠ” ë¡œì»¬ Qwen ëŒ€ì‹  OpenAI API ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
# =========================================================

# MODEL_NAME = "/home/alpaco/lhc/Qwen2.5-14B-Instruct"  # ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ê²½ë¡œ/ì´ë¦„
MODEL_NAME = "gpt-4.1-mini"  # OpenAI APIì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (í•„ìš”ì‹œ gpt-4o ë“±ìœ¼ë¡œ ë³€ê²½)

# 3 x 3090 (ê° 24GB) ê¸°ì¤€: 4bit ë¡œë“œ + device_map="auto"
# ğŸ‘‰ OpenAI API ì‚¬ìš© ì‹œì—ëŠ” ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì„¤ì •ì´ì§€ë§Œ,
#    ì›ë˜ ì½”ë“œ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_quant_type="nf4",
)

# GPU ë©”ëª¨ë¦¬ í•œë„ ì§€ì • (í•„ìš”ì‹œ)
# ğŸ‘‰ ë§ˆì°¬ê°€ì§€ë¡œ OpenAI APIì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
max_memory = {
    0: "20GiB",   # ì—¬ìœ ë¥¼ ì¡°ê¸ˆ ë‚¨ê²¨ë‘ê¸°
    1: "20GiB",
    2: "20GiB",
    "cpu": "32GiB",
}

print("Loading OpenAI client...")

# ğŸ”¹ OpenAI API í‚¤ ì„¤ì • (ì—¬ê¸°ì— ë³¸ì¸ í‚¤ ë„£ìœ¼ì„¸ìš”)
os.environ["OPENAI_API_KEY"] =""
#OPENAI_API_KEY=""

# ğŸ”¹ OpenAI Python SDK í´ë¼ì´ì–¸íŠ¸
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY")
)

# ğŸ”¹ ë¡œì»¬ Qwen ëª¨ë¸ì€ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ placeholder ë¡œ ë‘¡ë‹ˆë‹¤.
tokenizer = None
model = None

# Qwenì€ eos_token_id / pad_token_id ì„¤ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
# ğŸ‘‰ ì´ì œëŠ” ëª¨ë¸ì„ ì§ì ‘ ë¡œë“œí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì•„ë˜ if ë¸”ë¡ì€ ì˜ë¯¸ê°€ ì—†ì–´ì§‘ë‹ˆë‹¤.
#    í•˜ì§€ë§Œ ì›ë˜ ì½”ë“œ êµ¬ì¡°/ì£¼ì„ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ë‚¨ê²¨ ë‘¡ë‹ˆë‹¤.
if hasattr(torch, "Tensor"):  # í˜•ì‹ìƒ ì¡°ê±´ (ì‹¤ì œ ë™ì‘ X)
    pass


# =========================================================
# 1. SYSTEM PROMPT (í™•ì¥ëœ JSON ìŠ¤í‚¤ë§ˆ)
# =========================================================

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ì–´ ë ˆì‹œí”¼ ì¶”ì²œ ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œì¸
"ìš”ë¦¬ ì˜ë„Â·ì¡°ê±´ ì¶”ì¶œê¸°(Keyword & Constraint Extractor)" ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”:
ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ë¦¬ ìš”ì²­ì—ì„œ **ëª¨ë“  ì˜ë¯¸ ìˆëŠ” ìš”ì†Œë¥¼ ë¹ ì§ì—†ì´ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.

ì¶œë ¥ ê·œì¹™ì€ ë°˜ë“œì‹œ ë‹¤ìŒì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ **â‘  ì¶œë ¥ í˜•ì‹**

ì˜¤ì§ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆ í˜•íƒœì˜ JSONë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
ë¬¸ì¥ ì„¤ëª…, í•´ì„¤, ì¶”ê°€ ë¬¸êµ¬ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ë¬´ì¡°ê±´ ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•˜ì‹­ì‹œì˜¤.

ëª¨ë“  í•„ë“œëŠ” ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.
ê°’ì´ ë¹„ì—ˆìœ¼ë©´ **ë¹ˆ ë°°ì—´ ë˜ëŠ” null** ë¡œ ì±„ìš°ì‹­ì‹œì˜¤.

JSON ìŠ¤í‚¤ë§ˆ:

{
  "dish_type": [],                    // ìš”ë¦¬ í˜•íƒœ/ì¢…ë¥˜
  "method": [],                       // ì¡°ë¦¬ ë°©ì‹
  "situation": [],                    // ë¨¹ëŠ” ìƒí™©/ë§¥ë½
  "must_ingredients": [],             // ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ì¬ë£Œ
  "optional_ingredients": [],         // ë“¤ì–´ê°€ë©´ ì¢‹ì§€ë§Œ í•„ìˆ˜ëŠ” ì•„ë‹Œ ì¬ë£Œ
  "exclude_ingredients": [],          // ì ˆëŒ€ ë“¤ì–´ê°€ë©´ ì•ˆ ë˜ëŠ” ì¬ë£Œ
  "spiciness": "none" | "low" | "medium" | "high" | null,

  "dietary_constraints": {
    "vegetarian": bool,
    "vegan": bool,
    "no_beef": bool,
    "no_pork": bool,
    "no_chicken": bool,
    "no_seafood": bool
  },

  "servings": {
    "min": int or null,
    "max": int or null
  },

  "max_cook_time_min": int or null,
  "difficulty": [],

  "health_tags": [],                  // ê±´ê°•, ëª©ì , ì˜ì–‘ ê´€ë ¨
  "weather_tags": [],                 // ë‚ ì”¨/ê³„ì ˆ
  "menu_style": [],                   // êµ­ê°€/ë¶„ë¥˜/ìŠ¤íƒ€ì¼
  "extra_keywords": [],               // ìœ„ ì–´ë””ì—ë„ ì†í•˜ì§€ ì•ŠëŠ” ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´

  "positive_tags": [],                // ì‚¬ìš©ìê°€ ì›í•¨/ì¢‹ì•„í•¨
  "negative_tags": [],                // ì‚¬ìš©ìê°€ ì‹«ì–´í•¨/í”¼í•˜ê³  ì‹¶ìŒ

  "free_text": string                 // ì „ì²´ ìš”ì²­ì˜ ìì—°ì–´ ìš”ì•½
}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ **â‘¡ ê° í•„ë“œì˜ ì„¸ë¶€ ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)**

1) dish_type (ìš”ë¦¬ ì¢…ë¥˜)
- "ì°Œê°œ", "êµ­", "ë³¶ìŒ", "íŠ€ê¹€", "ì¡°ë¦¼", "ë®ë°¥", "ë¹„ë¹”ë°¥", "ë©´ ìš”ë¦¬" ë“±
- ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì  í‘œí˜„ìœ¼ë¡œ ì¶”ì¶œ

2) method (ì¡°ë¦¬ ë°©ì‹)
- "ë“ì´ê¸°", "ë³¶ê¸°", "ì°œ", "ë¬´ì¹¨", "íŠ€ê¸°ê¸°", "êµ½ê¸°" ë“±

3) situation (ë¨¹ëŠ” ìƒí™©)
- "ì•¼ì‹", "í˜¼ë°¥", "ìˆ ì•ˆì£¼", "ì†ë‹˜ ì´ˆëŒ€", "ê°„ë‹¨í•˜ê²Œ", "ë„ì‹œë½", "ìº í•‘" ë“±
- ë¬¸ë§¥ì—ì„œ ìˆ¨ê²¨ì§„ ìƒí™©ë„ ì¶”ë¡ í•˜ì—¬ í¬í•¨ ê°€ëŠ¥

4) must_ingredients ê·œì¹™(ì•„ì£¼ ì¤‘ìš”):

  ì‚¬ìš©ìê°€ íŠ¹ì • ì¬ë£Œë¥¼ ì–¸ê¸‰í•˜ë©° â€œ~ ìš”ë¦¬ ì¶”ì²œí•´ì¤˜â€, â€œ~ ë„£ì–´ ë¨¹ê³  ì‹¶ë‹¤â€, 
  â€œ~ë¡œ ë§Œë“¤ê³  ì‹¶ë‹¤â€, â€œ~ ìš”ë¦¬ê°€ ë•¡ê¸´ë‹¤â€, â€œ~ ìš”ë¦¬ ë¨¹ê³  ì‹¶ì–´â€ ë¼ê³  ë§í•œ ê²½ìš°
  â†’ í•´ë‹¹ ì¬ë£ŒëŠ” MUST INGREDIENTë¡œ ê°„ì£¼í•œë‹¤.

  ì˜ˆ:
  - â€œë¼ì§€ê³ ê¸° ìš”ë¦¬ ì¶”ì²œí•´ì¤˜â€ â†’ must_ingredients: ["ë¼ì§€ê³ ê¸°"]
  - â€œê¹€ì¹˜ë‘ ë²„ì„¯ì´ë‘ ê°™ì´ ë¨¹ê³  ì‹¶ë‹¤â€ â†’ must_ingredients: ["ê¹€ì¹˜","ë²„ì„¯"]
  - â€œë‹­ê³ ê¸°ë¡œ ë­˜ ë§Œë“¤ê¹Œ?â€ â†’ must_ingredients: ["ë‹­ê³ ê¸°"]

5) optional_ingredients
- â€œìˆìœ¼ë©´ ì¢‹ê³ â€, â€œê°€ëŠ¥í•˜ë©´â€, â€œì¶”ê°€ë¡œâ€ í‘œí˜„ëœ ì¬ë£Œ

6) exclude_ingredients
- â€œì‹«ì–´â€, â€œì•Œë ˆë¥´ê¸°â€, â€œëª»ë¨¹ì–´â€, â€œë¹¼ê³ â€, â€œì œì™¸í•´ì¤˜â€ ë“±

7) spiciness
- "ì•ˆ ë§¤ìš´", "ë§¤ì½¤í•˜ê²Œ", "ì–¼í°í•˜ê²Œ" ë“± í•´ì„í•˜ì—¬ 4ë‹¨ê³„ë¡œ ì •ê·œí™”:
  - none, low, medium, high

8) dietary_constraints
- "ì±„ì‹ì£¼ì˜ì" â†’ vegetarian=true + no_beef/no_pork/no_chicken/no_seafood=true, ì–´ë– í•œ í˜•íƒœì˜ ê³ ê¸°ìš”ë¦¬ë‚˜ ìƒì„ ìš”ë¦¬ë„ í¬í•¨ë˜ë©´ ì•ˆë¼
- "ë¹„ê±´" â†’ vegan=true + ìœ„ ì¡°ê±´ ëª¨ë‘ true
- â€œê³ ê¸° ì•ˆ ë¨¹ì–´â€ â†’ no_beef/no_pork/no_chicken ëª¨ë‘ true
- íŠ¹ì • ìœ¡ë¥˜ë§Œ ì‹«ì–´í•˜ë©´ í•´ë‹¹ í•­ëª©ë§Œ true

9) servings
- "1ì¸ë¶„", "í˜¼ì ë¨¹ì„ ê±°ì•¼" â†’ min=1, max=1
- "4ëª…", "ê°€ì¡±" â†’ ì¶”ë¡  ê°€ëŠ¥í•˜ë©´ ë„£ê³ , ë¶ˆí™•ì‹¤í•˜ë©´ null

10) max_cook_time_min
- "10ë¶„ ì•ˆì—", "ë¹¨ë¦¬", "ê°„ë‹¨íˆ" â†’ ëª…í™•íˆ ìˆ«ìê°€ ìˆì„ ë•Œë§Œ ê¸°ì…
- ìˆ«ìê°€ ì—†ìœ¼ë©´ null

11) difficulty
- "ê°„ë‹¨í•œ", "ì‰½ê²Œ", "ì–´ë ¤ìš´ ìš”ë¦¬" ë“± ë‚œì´ë„ í‘œí˜„ ê·¸ëŒ€ë¡œ ë‹¨ì–´ë¡œ ë„£ê¸°

12) health_tags
- "ë‹¤ì´ì–´íŠ¸", "ê³ ë‹¨ë°±", "ì €ì—¼ì‹", "ì €ì¹¼ë¡œë¦¬", "ì˜ì–‘ì‹" ë“±

13) weather_tags
- "ì¶”ìš´ ë‚ ", "ë”ìš´ ë‚ ", "ë¹„ì˜¤ëŠ” ë‚ ", "ê²¨ìš¸", "ì—¬ë¦„" ë“±

14) menu_style
- "í•œì‹", "ì¤‘ì‹", "ì–‘ì‹", "ë¶„ì‹", "ë””ì €íŠ¸", "ì•ˆì£¼", "ë¸ŒëŸ°ì¹˜", "í•œ ê·¸ë¦‡" ë“±

15) extra_keywords
- ìœ„ í•­ëª©ë“¤ ì–´ë””ì—ë„ ì†í•˜ì§€ ì•Šì§€ë§Œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´
  ì˜ˆ: "ë°±ì¢…ì› ë ˆì‹œí”¼", "ì—ì–´í”„ë¼ì´ì–´", "ëª…ì ˆ", "ì¹¼ì¹¼í•œ", "ê°„í¸ì‹"

16) positive_tags
- â€œì¢‹ì•„í•´â€, â€œë¨¹ê³  ì‹¶ì–´â€, â€œì›í•´â€, â€œ craving â€ ë“± ê°ì •/ì„ í˜¸ ê¸°ë°˜

17) negative_tags
- â€œì‹«ì–´â€, â€œë³„ë¡œâ€, â€œêº¼ë ¤ì ¸â€, "ë¨¹ê¸° ì‹«ì–´"

18) free_text
- ì „ì²´ ì‚¬ìš©ì ìš”ì²­ì„ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•œ 1~2ë¬¸ì¥
- ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ë‹¤ìŒ ë‚´ìš©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•¨:
  1) ì‚¬ìš©ìê°€ ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–¤ ì¢…ë¥˜ì˜ ìŒì‹ì„ ì›í•˜ê³  ìˆëŠ”ì§€
  2) ì¬ë£Œ/ì‹ë‹¨ ì œí•œ/ì·¨í–¥ ì¡°ê±´ì´ ì„œë¡œ ëª¨ìˆœë˜ê±°ë‚˜ ë¹„í˜„ì‹¤ì ì¸ì§€ ì—¬ë¶€
  3) ëª¨ìˆœÂ·ìœ„í—˜Â·ë¹„í˜„ì‹¤ì ì¸ ì¡°ê±´ì´ ìˆë‹¤ë©´,
     "ìš”ì²­ì„ ê·¸ëŒ€ë¡œ ë§Œì¡±ì‹œí‚¤ê¸° ì–´ë µë‹¤"ëŠ” ì ê³¼
     ì–´ë–¤ ë°©í–¥(ì˜ˆ: ë¹„ê±´ ìœ ì§€, ì•Œë ˆë¥´ê¸° íšŒí”¼ ë“±)ì„ ìš°ì„ í•´ì•¼ í•˜ëŠ”ì§€ ì œì•ˆ

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ **â‘¢ ì ˆëŒ€ì ìœ¼ë¡œ ì§€ì¼œì•¼ í•  3ê°€ì§€**

1. ì¶œë ¥ì€ ë°˜ë“œì‹œ **JSON ë‹¨ë…**ì´ì–´ì•¼ í•¨ (ì•ë’¤ ì¶”ê°€ í…ìŠ¤íŠ¸ ê¸ˆì§€)  
2. JSON ìŠ¤í‚¤ë§ˆì˜ **ëª¨ë“  í•„ë“œ**ë¥¼ ë°˜ë“œì‹œ ì¶œë ¥  
3. ë¹ˆ ê°’ë„ ë°˜ë“œì‹œ í¬í•¨ (ì ˆëŒ€ í•„ë“œ ëˆ„ë½ ê¸ˆì§€)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ì§€ê¸ˆë¶€í„° ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´
ìœ„ ìŠ¤í‚¤ë§ˆì— ë§ì¶° **ì •í™•í•˜ê³  ì™„ì „í•œ JSON**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
"""

# =========================================================
# 2. Post-process helpers
# =========================================================

def _ensure_list(x):
    if x is None:
        return []
    if isinstance(x, str):
        if not x.strip():
            return []
        return [x]
    return list(x)

def _unique_preserve_order(lst):
    seen = set()
    out = []
    for x in lst:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out

def _dedup_by_norm_space_lower(tags):
    """
    ['ì¶”ìš´ ë‚ ', 'ì¶”ìš´ë‚ '] ê°™ì´ ê³µë°±/ëŒ€ì†Œë¬¸ìë§Œ ë‹¤ë¥¸ ì¤‘ë³µì„ í•˜ë‚˜ë¡œ ì •ë¦¬.
    """
    norm_seen = set()
    out = []
    for t in _ensure_list(tags):
        norm = str(t).replace(" ", "").lower()
        if norm in norm_seen:
            continue
        norm_seen.add(norm)
        out.append(t)
    return out


def _postprocess_text_to_json(output_text: str, fallback_prompt: str) -> dict:
    """
    - LLMì´ ì¶œë ¥í•œ JSON í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±
    - ëˆ„ë½/íƒ€ì… ì´ìƒ í•„ë“œ ë³´ì •
    - positive_tags â†’ health_tags / extra_keywords í™•ì¥
    - weather_tagsëŠ” LLM ì¶œë ¥ë§Œ ì‚¬ìš©í•˜ë˜, í‘œê¸° ì¤‘ë³µë§Œ ì •ë¦¬
    """
    output_text = output_text.strip()

    # ```json ... ``` í˜•íƒœ ì œê±°
    if output_text.startswith("```"):
        output_text = output_text.strip("`").strip()
        if output_text.startswith("json"):
            output_text = output_text[4:].strip()

    try:
        data = json.loads(output_text)
    except json.JSONDecodeError:
        data = {}

    # 1) ê¸°ë³¸ ê³¨ê²© (í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ê¸°ì¤€)
    base = {
        "dish_type": [],
        "method": [],
        "situation": [],
        "must_ingredients": [],
        "optional_ingredients": [],
        "exclude_ingredients": [],
        "spiciness": None,
        "dietary_constraints": {
            "vegetarian": False,
            "vegan": False,
            "no_beef": False,
            "no_pork": False,
            "no_chicken": False,
            "no_seafood": False,
        },
        "servings": {"min": None, "max": None},
        "max_cook_time_min": None,
        "difficulty": [],

        "health_tags": [],
        "weather_tags": [],
        "menu_style": [],
        "extra_keywords": [],

        "positive_tags": [],
        "negative_tags": [],
        "free_text": fallback_prompt,
    }

    if not isinstance(data, dict):
        data = {}

    merged = base.copy()
    merged.update({k: v for k, v in data.items() if v is not None})

    # ë¦¬ìŠ¤íŠ¸ í•„ë“œ ì •ê·œí™”
    list_fields = [
        "dish_type", "method", "situation",
        "must_ingredients", "optional_ingredients", "exclude_ingredients",
        "difficulty",
        "health_tags", "weather_tags", "menu_style", "extra_keywords",
        "positive_tags", "negative_tags",
    ]
    for k in list_fields:
        merged[k] = _ensure_list(merged.get(k))

    # dietary_constraints ë³´ì •
    dc = merged.get("dietary_constraints") or {}
    merged["dietary_constraints"] = {
        "vegetarian": bool(dc.get("vegetarian", False)),
        "vegan": bool(dc.get("vegan", False)),
        "no_beef": bool(dc.get("no_beef", False)),
        "no_pork": bool(dc.get("no_pork", False)),
        "no_chicken": bool(dc.get("no_chicken", False)),
        "no_seafood": bool(dc.get("no_seafood", False)),
    }

    # servings ë³´ì •
    serv = merged.get("servings") or {}
    merged["servings"] = {
        "min": serv.get("min"),
        "max": serv.get("max"),
    }

    # spiciness ì •ê·œí™”
    valid_sp = {"none", "low", "medium", "high", None}
    sp = merged.get("spiciness")
    if isinstance(sp, str):
        sp = sp.lower().strip()
        if sp not in valid_sp:
            sp = None
    elif sp not in valid_sp:
        sp = None
    merged["spiciness"] = sp

    # free_text ë³´ì •
    if not isinstance(merged.get("free_text"), str) or not merged["free_text"].strip():
        merged["free_text"] = fallback_prompt

    # positive_tags â†’ health_tags / extra_keywords í™•ì¥
    pos = merged.get("positive_tags", [])
    merged["health_tags"] = _unique_preserve_order(merged["health_tags"] + pos)
    merged["extra_keywords"] = _unique_preserve_order(merged["extra_keywords"] + pos)

    # weather_tagsëŠ” LLM ì¶œë ¥ë§Œ ì‹ ë¢°, ëŒ€ì‹  ê³µë°±/ëŒ€ì†Œë¬¸ì ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    merged["weather_tags"] = _dedup_by_norm_space_lower(merged["weather_tags"])

    return merged


# =========================================================
# 3. ì‹¤ì œ í˜¸ì¶œ í•¨ìˆ˜: extract_keywords (ì›ë˜ chat_template ë°©ì‹ ìœ ì§€ â†’ OpenAI APIë¡œ ë³€ê²½)
# =========================================================

def extract_keywords(user_prompt: str) -> dict:
    """
    í•œêµ­ì–´ ììœ  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ë ˆì‹œí”¼ ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œ.
    - ê¸°ì¡´ì—ëŠ” 4bit Qwen2.5-14B (multi-GPU) ì‚¬ìš©
    - ì´ì œëŠ” OpenAI Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬
      SYSTEM_PROMPTì— ì •ì˜ëœ í™•ì¥ ìŠ¤í‚¤ë§ˆë¡œ
      health_tags / weather_tags / menu_style / extra_keywordsê¹Œì§€ í¬í•¨
    """

    # OpenAI Responses APIëŠ” instructions + input ì¡°í•©ìœ¼ë¡œ
    # system / user ì—­í• ì„ ì¤„ ìˆ˜ ìˆìŒ.
    # - instructions: SYSTEM_PROMPT (ì—­í• /ìŠ¤í‚¤ë§ˆ ì„¤ëª…)
    # - input: ì‹¤ì œ user_prompt
    response = client.responses.create(
        model=MODEL_NAME,
        instructions=SYSTEM_PROMPT,
        input=user_prompt,
        temperature=0.0,        # JSON í¬ë§· ìœ ì§€ ìœ„í•´ ìµœëŒ€í•œ ê²°ì •ì ìœ¼ë¡œ
        max_output_tokens=256,  # ì›ë˜ max_new_tokens=128ë³´ë‹¤ëŠ” ì•½ê°„ ì—¬ìœ 
    )

    # ëª¨ë¸ì´ ìƒì„±í•œ ìˆœìˆ˜ í…ìŠ¤íŠ¸(JSON ë¬¸ìì—´)
    output_text = response.output_text or ""

    return _postprocess_text_to_json(output_text, fallback_prompt=user_prompt)


# íŒŒì¼ ë§¨ ì•„ë˜ ê·¼ì²˜
__all__ = ["extract_keywords", "tokenizer", "model"]


import csv
import os

# ê²°ê³¼ë¥¼ ì €ì¥í•  CSV ê²½ë¡œ (ì›í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ ë°”ê¿”ë„ ë©ë‹ˆë‹¤)
CSV_PATH = "keyword_extract_log.csv"


def _join_list(x):
    """ë¦¬ìŠ¤íŠ¸ë¥¼ ' | 'ë¡œ ì´ì–´ë¶™ì—¬ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if isinstance(x, list):
        return " | ".join(map(str, x))
    return ""


def result_to_row(user_prompt: str, result: dict) -> dict:
    """
    extract_keywords() ê²°ê³¼ dictë¥¼
    CSV í•œ ì¤„(row) í˜•íƒœì˜ flat dictë¡œ ë³€í™˜
    """
    dc = result.get("dietary_constraints", {}) or {}
    serv = result.get("servings", {}) or {}

    row = {
        "user_prompt": user_prompt,

        # ë¦¬ìŠ¤íŠ¸ í•„ë“œë“¤: " | " ë¡œ join
        "dish_type": _join_list(result.get("dish_type", [])),
        "method": _join_list(result.get("method", [])),
        "situation": _join_list(result.get("situation", [])),
        "must_ingredients": _join_list(result.get("must_ingredients", [])),
        "optional_ingredients": _join_list(result.get("optional_ingredients", [])),
        "exclude_ingredients": _join_list(result.get("exclude_ingredients", [])),
        "difficulty": _join_list(result.get("difficulty", [])),
        "health_tags": _join_list(result.get("health_tags", [])),
        "weather_tags": _join_list(result.get("weather_tags", [])),
        "menu_style": _join_list(result.get("menu_style", [])),
        "extra_keywords": _join_list(result.get("extra_keywords", [])),
        "positive_tags": _join_list(result.get("positive_tags", [])),
        "negative_tags": _join_list(result.get("negative_tags", [])),

        # ë‹¨ì¼ ê°’ë“¤
        "spiciness": result.get("spiciness", None),

        # diet ì œì•½ (bool)
        "vegetarian": dc.get("vegetarian", False),
        "vegan": dc.get("vegan", False),
        "no_beef": dc.get("no_beef", False),
        "no_pork": dc.get("no_pork", False),
        "no_chicken": dc.get("no_chicken", False),
        "no_seafood": dc.get("no_seafood", False),

        # ì¸ë¶„ ì •ë³´
        "servings_min": serv.get("min", None),
        "servings_max": serv.get("max", None),

        # ì‹œê°„, free_text
        "max_cook_time_min": result.get("max_cook_time_min", None),
        "free_text": result.get("free_text", ""),
    }
    return row


def save_result_to_csv(user_prompt: str, result: dict, csv_path: str = CSV_PATH):
    """
    - user_prompt + extract_keywords ê²°ê³¼ë¥¼ í•œ ì¤„(row)ë¡œ ë§Œë“¤ì–´ì„œ
      csv_pathì— í•œ ì¤„ì”© ì¶”ê°€(append) ì €ì¥
    - íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ë¥¼ ë¨¼ì € ì“°ê³ , ìˆìœ¼ë©´ í—¤ë” ì—†ì´ ë‚´ìš©ë§Œ ì¶”ê°€
    """
    row = result_to_row(user_prompt, result)
    file_exists = os.path.isfile(csv_path)

    with open(csv_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=row.keys())
        if not file_exists:
            writer.writeheader()
        writer.writerow(row)


def run_and_log(user_prompt: str, csv_path: str = CSV_PATH):
    """
    í¸í•˜ê²Œ ì“°ë¼ê³  ë§Œë“  í—¬í¼ í•¨ìˆ˜:
    - extract_keywords(user_prompt) ì‹¤í–‰
    - ê²°ê³¼ë¥¼ CSVì— ì €ì¥
    - ê²°ê³¼ dictë¥¼ ê·¸ëŒ€ë¡œ ë¦¬í„´
    """
    result = extract_keywords(user_prompt)
    save_result_to_csv(user_prompt, result, csv_path=csv_path)
    return result

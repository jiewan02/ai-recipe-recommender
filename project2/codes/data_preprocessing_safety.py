import json
import time
from typing import List, Dict

import pandas as pd
from tqdm import tqdm
from openai import OpenAI
from dotenv import load_dotenv
import os

# =========================
# 0. ì„¤ì •
# =========================

INPUT_CSV = "dataset_part2.csv"         # ë„¤ ì›ë³¸ csv ê²½ë¡œ
OUTPUT_CSV = "recipes_with_tags.csv"    # ìµœì¢… ê²°ê³¼ csv ê²½ë¡œ
PARTIAL_META_CSV = "recipes_with_tags_meta_partial.csv"  # ì¤‘ê°„ ë©”íƒ€ ê²°ê³¼ ì €ì¥
MODEL_NAME = "gpt-4o-mini"              # í•„ìš”í•˜ë©´ gpt-5.1, gpt-5.1-mini ë“±ìœ¼ë¡œ ë³€ê²½
BATCH_SIZE = 20                         # í•œ ë²ˆì— ë³´ë‚¼ ë ˆì‹œí”¼ ê°œìˆ˜ (ë¹„ìš©/ì†ë„ ë”°ë¼ ì¡°ì •)

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)


# =========================
# 1. í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
# =========================
def build_batch_input(batch_df: pd.DataFrame) -> str:
    """
    í•œ batchì˜ ë ˆì‹œí”¼ ì •ë³´ë¥¼ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ ëª¨ë¸ input í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©.
    """
    records: List[Dict] = []
    for _, row in batch_df.iterrows():
        record = {
            "recipe_id": int(row["ë ˆì‹œí”¼ì¼ë ¨ë²ˆí˜¸"]),
            "title": str(row.get("ë ˆì‹œí”¼ì œëª©", "")),
            "name": str(row.get("ìš”ë¦¬ëª…", "")),
            "views": int(row.get("ì¡°íšŒìˆ˜", 0)) if pd.notna(row.get("ì¡°íšŒìˆ˜", None)) else 0,
            "cook_method": str(row.get("ìš”ë¦¬ë°©ë²•ì„¤ëª…", "")),     # ë“ì´ê¸°, ë³¶ê¸° ë“±
            "situation": str(row.get("ìš”ë¦¬ìƒí™©ì„¤ëª…", "")),      # ëª…ì ˆ, ìˆ ì•ˆì£¼, ì§‘ë“¤ì´ ë“±
            "type": str(row.get("ìš”ë¦¬ì¢…ë¥˜ë³„ëª…", "")),           # ['êµ­','íƒ•'] ì´ëŸ° ì •ë³´
            "intro": str(row.get("ìš”ë¦¬ì†Œê°œ_clean", row.get("ìš”ë¦¬ì†Œê°œ", ""))),
            "ingredients_text": str(row.get("ìš”ë¦¬ì¬ë£Œë‚´ìš©", "")), # [ì¬ë£Œ] ~ í˜•ì‹
            "servings": str(row.get("ìš”ë¦¬ì¸ë¶„ëª…", "")),         # 2ì¸ë¶„ ë“±
            "difficulty": str(row.get("ìš”ë¦¬ë‚œì´ë„ëª…", "")),      # ì´ˆê¸‰, ì¤‘ê¸‰ ë“±
            "time": str(row.get("ìš”ë¦¬ì‹œê°„ëª…", "")),             # 30ë¶„ ì´ë‚´, 2ì‹œê°„ì´ë‚´ ë“±
        }
        records.append(record)

    return json.dumps(records, ensure_ascii=False, indent=2)


INSTRUCTIONS = """
ë„ˆëŠ” í•œêµ­ ìš”ë¦¬ ë ˆì‹œí”¼ ë©”íƒ€ë°ì´í„° íƒœê¹… ì „ë¬¸ê°€ë‹¤.

ì…ë ¥ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ë ˆì‹œí”¼ê°€ JSON ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì£¼ì–´ì§„ë‹¤.
ê° ë ˆì‹œí”¼ì— ëŒ€í•´ ì•„ë˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ **ë°˜ë“œì‹œ JSON ë¦¬ìŠ¤íŠ¸**ë¡œ ë°˜í™˜í•´ë¼.

ê° ì›ì†ŒëŠ” ë‹¤ìŒ í˜•íƒœì˜ JSON ê°ì²´ì—¬ì•¼ í•œë‹¤:

{
  "recipe_id": <int>,                 // ì…ë ¥ì—ì„œ ë°›ì€ ë ˆì‹œí”¼ì¼ë ¨ë²ˆí˜¸
  "health_tags": [                    // ê±´ê°•/ì˜ì–‘ ê´€ë ¨ íƒœê·¸ (0ê°œ ì´ìƒ)
    "ë‹¤ì´ì–´íŠ¸", "ê³ ì¹¼ë¡œë¦¬", "ì €ì¹¼ë¡œë¦¬", "ì €ì—¼ì‹", "ê³ ë‹¨ë°±", "ì €íƒ„ìˆ˜",
    "ì±„ì‹", "ë¹„ê±´", "ì €ì§€ë°©", "ê³ ì„¬ìœ ì§ˆ", "í‚¤ì¦ˆë©”ë‰´", "ìˆ ì•ˆì£¼"
  ì¤‘ì—ì„œ í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ ì„ íƒ],
  "weather_tags": [                   // ë‚ ì”¨/ê³„ì ˆ íƒœê·¸ (0ê°œ ì´ìƒ)
    "ì¶”ìš´ë‚ ", "ë”ìš´ë‚ ", "ë¹„ì˜¤ëŠ”ë‚ ", "ëˆˆì˜¤ëŠ”ë‚ ",
    "ë³µë‚ ", "ê²¨ìš¸", "ì—¬ë¦„", "ë´„", "ê°€ì„", "ì¥ë§ˆì² "
  ì¤‘ì—ì„œ í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ ì„ íƒ],
  "menu_style": [                     // ë©”ë‰´ ìŠ¤íƒ€ì¼/ì¹´í…Œê³ ë¦¬ (0ê°œ ì´ìƒ)
    "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "í“¨ì „",
    "ë¶„ì‹", "ë””ì €íŠ¸", "ì•¼ì‹", "ì•ˆì£¼", "ê°„ì‹", "ë„ì‹œë½"
  ì¤‘ì—ì„œ í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ ì„ íƒ],
  "extra_keywords": [                 // ìš”ë¦¬ì†Œê°œ, ìƒí™©, ì¬ë£Œì—ì„œ ì¶”ê°€ë¡œ ë½‘ì„ í•µì‹¬ í‚¤ì›Œë“œ (ììœ  í˜•ì‹, 0~10ê°œ)
    "ëª…ì ˆìŒì‹", "ìƒˆí•´ë–¡êµ­", "ë”°ëœ»í•œêµ­ë¬¼", ...
  ]
}

ì£¼ì˜ì‚¬í•­:
- ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥í•´ë¼. ì„¤ëª… ë¬¸ì¥, ì£¼ì„, ì½”ë“œë¸”ë¡ í‘œì‹œ, í•œêµ­ì–´ ì„¤ëª… ë“±ì„ ì ˆëŒ€ ì„ì§€ ë§ˆë¼.
- ê° recipe_idëŠ” ì…ë ¥ì˜ recipe_idì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•œë‹¤.
- íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ë¬¸ìì—´ì€ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•´ë¼.
- í•´ë‹¹í•˜ì§€ ì•ŠëŠ” íƒœê·¸ëŠ” í¬í•¨í•˜ì§€ ë§ê³ , ì™„ì „ ëª¨ë¥¼ ë•ŒëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸[]ë¡œ ë‘”ë‹¤.
"""


# =========================
# 1-1. OpenAI í˜¸ì¶œ + ì¬ì‹œë„ ë¡œì§
# =========================
def call_openai_for_batch(batch_df: pd.DataFrame) -> List[Dict]:
    batch_input = build_batch_input(batch_df)

    # ì¬ì‹œë„ íšŸìˆ˜ ëŠ˜ë¦¼: 6íšŒ
    max_attempts = 10
    last_exception = None

    for attempt in range(max_attempts):
        raw_text = ""  # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ë³€ìˆ˜ ì¡´ì¬í•˜ë„ë¡ ì´ˆê¸°í™”
        try:
            response = client.responses.create(
                model=MODEL_NAME,
                instructions=INSTRUCTIONS,
                input=batch_input,
                max_output_tokens=2048,
            )

            # Responses API output íŒŒì‹±
            raw_text_parts = []
            for out in response.output:
                for content in out.content:
                    if content.type == "output_text":
                        raw_text_parts.append(content.text)
            raw_text = "".join(raw_text_parts)

            if not raw_text.strip():
                raise ValueError(f"[API ERROR] ë¹ˆ ì‘ë‹µ. response={response}")

            # JSON íŒŒì‹±
            data = json.loads(raw_text)
            return data

        except Exception as e:
            last_exception = e
            print(f"[WARN] OpenAI í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_attempts}): {e}")
            if raw_text:
                print("raw_text (ì•ë¶€ë¶„) =", raw_text[:200])
            # exponential backoff
            sleep_sec = 3 * (attempt + 1)
            print(f"â†’ {sleep_sec}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
            time.sleep(sleep_sec)

    # ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ë©´ ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨
    print("[ERROR] OpenAI API í˜¸ì¶œì´ ëª¨ë“  ì¬ì‹œë„ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    raise RuntimeError(f"OpenAI API ì‹¤íŒ¨: {last_exception}")


# =========================
# 1-2. ì¤‘ê°„ ê²°ê³¼ ì €ì¥ í•¨ìˆ˜
# =========================
def save_partial_results(all_results: List[Dict], filename: str = PARTIAL_META_CSV):
    """
    ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘í•œ all_resultsë¥¼ meta-only CSVë¡œ ì¤‘ê°„ ì €ì¥.
    ì„¸ì…˜ì´ ëŠê²¨ë„ ì´ íŒŒì¼ì€ ë‚¨ì•„ ìˆê²Œ ë¨.
    """
    if not all_results:
        return

    meta_df = pd.DataFrame(all_results)

    # ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ë“¤ì„ CSVì—ì„œ ë‹¤ë£¨ê¸° ì‰½ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì˜ˆ: "íƒœê·¸1|íƒœê·¸2")
    for col in ["health_tags", "weather_tags", "menu_style", "extra_keywords"]:
        if col in meta_df.columns:
            meta_df[col] = meta_df[col].apply(
                lambda x: "|".join(x) if isinstance(x, list) else (x if isinstance(x, str) else "")
            )

    meta_df.to_csv(filename, index=False)
    print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {filename} (rows={len(meta_df)})")


# =========================
# 2. ë©”ì¸ ë¡œì§
# =========================
def main():
    # ì›ë³¸ ë°ì´í„° ì½ê¸°
    df = pd.read_csv(INPUT_CSV)

    all_results: List[Dict] = []

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìˆœíšŒ
    for start in tqdm(range(0, len(df), BATCH_SIZE), desc="Processing batches"):
        end = min(start + BATCH_SIZE, len(df))
        batch_df = df.iloc[start:end]
        print(f"\n=== ë°°ì¹˜ ì²˜ë¦¬: rows {start} ~ {end-1} ===")

        try:
            batch_results = call_openai_for_batch(batch_df)
        except Exception as e:
            # ì´ ë°°ì¹˜ì—ì„œ ì´ ì‹¤íŒ¨í–ˆì§€ë§Œ, ì§€ê¸ˆê¹Œì§€ì˜ ê²°ê³¼ëŠ” ì¤‘ê°„ ì €ì¥
            print(f"[ERROR] ë°°ì¹˜ {start}~{end-1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜, ì´ ë°°ì¹˜ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤: {e}")
            save_partial_results(all_results)
            # ê³„ì† ì§„í–‰í• ì§€, ì—¬ê¸°ì„œ ë©ˆì¶œì§€ ì„ íƒ ê°€ëŠ¥
            # ì—¬ê¸°ì„œëŠ” ê³„ì† ì§„í–‰ (ë‹¤ìŒ ë°°ì¹˜ ì‹œë„)
            continue

        # ì •ìƒ ì‘ë‹µì„ all_resultsì— ì¶”ê°€
        all_results.extend(batch_results)

        # ê° ë°°ì¹˜ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ (ì›í•˜ë©´ Në°°ì¹˜ë§ˆë‹¤ë¡œ ë°”ê¿”ë„ ë¨)
        save_partial_results(all_results)

        # API ì‚¬ìš©ëŸ‰ì´ ë„ˆë¬´ í¬ì§€ ì•Šë„ë¡ ì•½ê°„ì˜ sleep (í•„ìš”ì— ë”°ë¼ ì¡°ì •/ì‚­ì œ)
        time.sleep(0.5)

    # ìµœì¢… meta_df ìƒì„±
    if not all_results:
        print("[WARN] ìˆ˜ì§‘ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    meta_df = pd.DataFrame(all_results)

    # ë¦¬ìŠ¤íŠ¸ â†’ ë¬¸ìì—´ ë³€í™˜
    for col in ["health_tags", "weather_tags", "menu_style", "extra_keywords"]:
        if col in meta_df.columns:
            meta_df[col] = meta_df[col].apply(
                lambda x: "|".join(x) if isinstance(x, list) else (x if isinstance(x, str) else "")
            )

    # recipe_id ê¸°ì¤€ìœ¼ë¡œ ì›ë³¸ dfì™€ ë¨¸ì§€
    meta_df.rename(columns={"recipe_id": "ë ˆì‹œí”¼ì¼ë ¨ë²ˆí˜¸"}, inplace=True)
    merged = df.merge(meta_df, on="ë ˆì‹œí”¼ì¼ë ¨ë²ˆí˜¸", how="left")

    # ìµœì¢… CSV ì €ì¥
    merged.to_csv(OUTPUT_CSV, index=False)
    print(f"âœ… ì™„ë£Œ! ìµœì¢… ê²°ê³¼ë¥¼ {OUTPUT_CSV} ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


def test_api():
    resp = client.responses.create(
        model="gpt-4o-mini",
        input="API ì—°ê²°ì´ ì˜ ë˜ë©´ ì´ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ì¤˜."
    )
    print(resp.output_text)


if __name__ == "__main__":
    # test_api()
    main()